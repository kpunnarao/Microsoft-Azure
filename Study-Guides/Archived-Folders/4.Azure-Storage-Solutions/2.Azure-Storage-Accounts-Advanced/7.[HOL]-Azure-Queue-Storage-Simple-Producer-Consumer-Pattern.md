# Lab: Azure Queue Storage - Simple Producer-Consumer Pattern ðŸ“§

## Lab Scenario ðŸ”„

You want to demonstrate how Azure Queue Storage can be used to decouple application components, allowing a "producer" to send messages asynchronously to a "consumer." 

This is a fundamental pattern for building scalable and resilient cloud applications.

In this lab, you will:

1.  Reuse (or create) an Azure Storage Account.
2.  Create an Azure Queue within that storage account.
3.  Use Azure CLI (as a simple producer) to send messages to the queue.
4.  Create a basic Azure Function (as a consumer) that is triggered by messages arriving in the queue, processes them, and logs their content.
5.  Observe the asynchronous processing.
6.  Clean up all created resources.

**Resources you'll be creating in Azure:**

  * **Existing/New Resource Group**: `rg-storage-lab` (or similar from Previous Lab)
  * **Existing/New Storage Account**: `storagenameyouruniqueid` (from 4.[HOL]-Creating-an-Azure-Storage-Account or a new one)
  * **New Azure Queue**: `myprocessingqueue`
  * **New Azure Function App**: `func-queueconsumer-youruniqueid` (This will create an associated Storage Account for the Function App's internal use, and an Application Insights resource).

-----

## Part 1: Prerequisites

1.  **Azure Account**: An active Azure subscription.

2.  **Azure CLI or Azure PowerShell**: Installed and logged in.

3.  **An Existing Azure Storage Account**:

      * You can reuse the storage account from Lab 1 (`storagenameyouruniqueid` in `rg-storage-lab`).
      * **If you deleted it or don't have one**: Please re-create it by following **4.[HOL]-Creating-an-Azure-Storage-Account** steps. Make sure to use a globally unique name.

    *Example command to re-create if needed (replace placeholders):*

    ```bash
    # Azure CLI
    az group create --name rg-storage-lab --location eastus
    az storage account create \
      --name storagenameyouruniqueid \
      --resource-group rg-storage-lab \
      --location eastus \
      --sku Standard_LRS \
      --kind StorageV2 \
      --access-tier Hot
    ```

    ```powershell
    # Azure PowerShell
    New-AzResourceGroup -Name "rg-storage-lab" -Location "EastUS"
    New-AzStorageAccount -ResourceGroupName "rg-storage-lab" `
      -Name "storagenameyouruniqueid" `
      -Location "EastUS" `
      -SkuName "Standard_LRS" `
      -Kind "StorageV2" `
      -AccessTier "Hot"
    ```

-----

## Part 2: Create an Azure Queue

We'll create a queue named `myprocessingqueue`.

**(Choose one method: Azure Portal, Azure CLI, or Azure PowerShell)**

**2.1. Azure Portal Method**

1.  Sign in to the [Azure Portal](https://portal.azure.com/).
2.  Navigate to your Storage Account (e.g., `storagenameyouruniqueid` in `rg-storage-lab`).
3.  In the left menu of the storage account, under **Data storage**, select **Queues**.
4.  Click **+ Queue**.
5.  **Name**: Enter `myprocessingqueue`.
6.  Click **OK**.
7.  You should see `myprocessingqueue` listed in your queues.

**2.2. Azure CLI Method**

1.  Open your terminal or Cloud Shell.
2.  Set variables (replace `storagenameyouruniqueid`):
    ```bash
    RESOURCE_GROUP="rg-storage-lab"
    STORAGE_ACCOUNT_NAME="storagenameyouruniqueid" # Your unique name from Part 1
    QUEUE_NAME="myprocessingqueue"
    ```
3.  Create the queue:
    ```bash
    az storage queue create \
      --name $QUEUE_NAME \
      --account-name $STORAGE_ACCOUNT_NAME \
      --resource-group $RESOURCE_GROUP \
      --output none
    echo "Queue '$QUEUE_NAME' created."
    ```

**2.3. Azure PowerShell Method**

1.  Open PowerShell.
2.  Set variables (replace `storagenameyouruniqueid` and `rg-storage-lab`):
    ```powershell
    $resourceGroupName = "rg-storage-lab"
    $storageAccountName = "storagenameyouruniqueid" # Your unique name from Part 1
    $queueName = "myprocessingqueue"

    $ctx = (Get-AzStorageAccount -ResourceGroupName $resourceGroupName -Name $storageAccountName).Context
    ```
3.  Create the queue:
    ```powershell
    New-AzStorageQueue -Name $queueName -Context $ctx
    Write-Host "Queue '$queueName' created."
    ```

-----

## Part 3: Send Messages to the Queue (Producer)

We'll use the Azure CLI to simulate a producer sending messages.

**3.1. Get Storage Account Connection String**

You'll need the connection string for your storage account to send messages.

**(Choose one method: Azure Portal, Azure CLI, or Azure PowerShell)**

**Portal:**

1.  Navigate to your Storage Account.
2.  In the left menu, under **Security + networking**, select **Access keys**.
3.  Click **Show keys**.
4.  Copy the **Connection string** for `key1`. It will start with `DefaultEndpointsProtocol=https;...`.

**Azure CLI:**

```bash
RESOURCE_GROUP="rg-storage-lab"
STORAGE_ACCOUNT_NAME="storagenameyouruniqueid"
CONNECTION_STRING=$(az storage account show-connection-string \
  --name $STORAGE_ACCOUNT_NAME \
  --resource-group $RESOURCE_GROUP \
  --query 'connectionString' \
  --output tsv)
echo "Connection String: $CONNECTION_STRING"
```

**Azure PowerShell:**

```powershell
$resourceGroupName = "rg-storage-lab"
$storageAccountName = "storagenameyouruniqueid"
$connectionString = (Get-AzStorageAccount -ResourceGroupName $resourceGroupName -Name $storageAccountName).Context.ConnectionString
Write-Host "Connection String: $connectionString"
```

**Copy this connection string; you will need it shortly.**

**3.2. Send Messages using Azure CLI**

Now, send a few messages to the queue.

1.  Open your terminal or Cloud Shell.

2.  Set the `AZURE_STORAGE_CONNECTION_STRING` environment variable with the connection string you just copied.

      * **Bash/Zsh (Linux/macOS/Cloud Shell):**
        ```bash
        export AZURE_STORAGE_CONNECTION_STRING="<YourStorageAccountConnectionString>"
        ```
      * **PowerShell:**
        ```powershell
        $env:AZURE_STORAGE_CONNECTION_STRING="<YourStorageAccountConnectionString>"
        ```
      * **Windows Command Prompt:**
        ```cmd
        set AZURE_STORAGE_CONNECTION_STRING="<YourStorageAccountConnectionString>"
        ```
      * **Important**: Replace `<YourStorageAccountConnectionString>` with the actual connection string.

3.  Send messages:

    ```bash
    # Send message 1
    az storage message put --queue-name myprocessingqueue --content "Hello from Producer 1!"

    # Send message 2
    az storage message put --queue-name myprocessingqueue --content "Process this data: Item A"

    # Send message 3
    az storage message put --queue-name myprocessingqueue --content "Final message for processing."
    ```

    You should see output indicating the messages were put into the queue.

4.  **Verify Messages in Portal (Optional):**

      * In the Azure Portal, navigate to your Storage Account -\> **Queues** -\> `myprocessingqueue`.
      * Click **Refresh**. You should see the "Approximate message count" increase (it might not be exact immediately).
      * You can also click **Browse** to see the messages (though they might disappear quickly once the consumer is active).

-----

## Part 4: Create an Azure Function (Consumer)

We'll create a simple Azure Function that is triggered whenever a new message arrives in `myprocessingqueue`.

**4.1. Create a Function App**

1.  In the Azure Portal, search for `Function App` and select it.
2.  Click **+ Create**.
3.  **Basics Tab**:
      * **Subscription**: Your subscription.
      * **Resource Group**: Select `rg-storage-lab`.
      * **Function App name**: Enter a globally unique name, e.g., `func-queueconsumer-youruniqueid` (replace `youruniqueid` with something unique to you).
      * **Publish**: `Code`
      * **Runtime stack**: `Node.js` (or `Python` if you prefer, the logic is simple)
      * **Version**: `18 LTS` (or latest recommended)
      * **Region**: Same as your storage account (e.g., `East US`).
      * **Operating System**: `Windows` (or `Linux` if you prefer).
      * **Plan type**: `Consumption (Serverless)` (cost-effective for this lab).
4.  **Hosting Tab**:
      * **Storage account**: Click `Create new` and accept the default name (this is for the Function App's internal use, not your `storagenameyouruniqueid`).
      * **Operating System**: `Windows` (or `Linux`).
      * **Plan**: `Consumption (Serverless)`.
5.  **Monitoring Tab**:
      * **Enable Application Insights**: `Yes` (accept default name). This is crucial for viewing logs.
6.  Click **Review + create**.
7.  After validation passes, click **Create**.
8.  Wait for the deployment to complete.

**4.2. Create a Queue Triggered Function**

1.  Once the Function App deployment is complete, navigate to your new Function App (`func-queueconsumer-youruniqueid`) in the Azure Portal.

2.  In the left menu, select **Functions** -\> **+ Create**.

3.  **Development environment**: Select `Develop in portal`.

4.  **Select a template**: Search for `Azure Queue Storage trigger` and select it.

5.  **Template details**:

      * **New Function**: Enter `QueueProcessor`.
      * **Queue name**: Enter `myprocessingqueue` (this must match the queue you created).
      * **Storage account connection**:
          * Click `+ New`.
          * **Name**: Enter `AzureWebJobsStorageQueue`.
          * **Storage account**: Select your existing storage account (`storagenameyouruniqueid`).
          * Click **OK**.
      * Click **Create**.

6.  **Review the Function Code**:

      * The portal will open the `QueueProcessor` function's `index.js` (or `__init__.py` for Python) file.
      * The default code is usually sufficient for this lab. It typically logs the message content.
      * For Node.js, it might look like:
        ```javascript
        module.exports = async function (context, myQueueItem) {
            context.log('JavaScript queue trigger function processed work item', myQueueItem);
        };
        ```
      * For Python, it might look like:
        ```python
        import logging
        import azure.functions as func

        app = func.FunctionApp()

        @app.queue_trigger(arg_name="myqueue", queue_name="myprocessingqueue",
                           connection="AzureWebJobsStorageQueue")
        def QueueProcessor(myqueue: func.QueueMessage):
            logging.info('Python queue trigger function processed a message: %s',
                         myqueue.get_body().decode('utf-8'))
        ```
      * No changes are needed for this lab.

-----

## Part 5: Test the Producer-Consumer Flow

Now, let's send messages and watch the Function App process them.

1.  **Monitor Function Logs**:

      * In the Azure Portal, navigate to your Function App (`func-queueconsumer-youruniqueid`).
      * In the left menu, select **Functions** -\> `QueueProcessor`.
      * Click **Monitor**. You might see a "Logs" section appear. If not, wait a moment or click "Configure" to enable streaming logs.
      * Keep this window open to see the real-time logs.

2.  **Send Messages Again (Producer)**:

      * Go back to your terminal or Cloud Shell where you set the `AZURE_STORAGE_CONNECTION_STRING`.
      * Send the messages again:
        ```bash
        az storage message put --queue-name myprocessingqueue --content "New message 1 for Function."
        az storage message put --queue-name myprocessingqueue --content "Another message for processing."
        az storage message put --queue-name myprocessingqueue --content "Final test message."
        ```
      * You can send these messages one by one or all at once.

3.  **Observe Function Processing**:

      * Switch back to the Function App's **Monitor** tab in the Azure Portal.
      * Within a few seconds, you should see log entries appearing, indicating that the `QueueProcessor` function received and processed each message. The log output will include the content of the message.
      * This demonstrates the asynchronous decoupling: you sent messages, and the Function App automatically picked them up and processed them without direct interaction at the time of sending.

-----

## Part 6: Cleaning Up Resources (Critical\!)

To avoid incurring ongoing costs, it's crucial to delete all resources created for this lab. The easiest way is to delete the resource group.

**(Choose one method: Azure Portal, Azure CLI, or Azure PowerShell)**

**6.1. Azure Portal Method**

1.  In the Azure Portal, search for `Resource groups` and select it.
2.  Find and click on your resource group: `rg-storage-lab`.
3.  On the resource group's Overview blade, click **Delete resource group**.
4.  Type the resource group name (`rg-storage-lab`) to confirm, then click **Delete**.
5.  This will delete your Storage Account, Queue, Function App, and all associated resources (like the Function App's storage account and Application Insights).

**6.2. Azure CLI Method**

1.  Open your terminal or Cloud Shell.
2.  ```bash
    RESOURCE_GROUP="rg-storage-lab"
    az group delete --name $RESOURCE_GROUP --no-wait --yes
    echo "Resource group '$RESOURCE_GROUP' deletion initiated."
    ```

**6.3. Azure PowerShell Method**

1.  Open PowerShell.
2.  ```powershell
    $resourceGroupName = "rg-storage-lab"
    Remove-AzResourceGroup -Name $resourceGroupName -Force -AsJob
    Write-Host "Resource group '$resourceGroupName' deletion initiated."
    ```

-----

Congratulations\! You have successfully implemented a simple producer-consumer pattern using Azure Queue Storage and Azure Functions. 

This lab highlights the power of asynchronous messaging for building scalable and decoupled cloud applications.